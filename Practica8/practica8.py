# -*- coding: utf-8 -*-
"""Practica8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GQP9eAJ3sTiB8JcCkhSPKlEnzObIanJu
"""

from sklearn.metrics import mean_squared_error
import pandas as pd
import matplotlib.pyplot as plt
from sympy.abc import x
import numpy as np
import sympy
import random as rd
 
class GaussJordan():
 
    def intercambiarFilas(self, index1, index2, M): 
        M[index1],M[index2]=M[index2],M[index1]
        return M
   
    def multiplicarFila(self, k, fila, colInicial, M):
        M[fila] = k * M[fila]
        return M
 
    def restarFilas(self, f1, f2, M):
        M[f1] =  M[f2] - M[f1]
        return M 
 
    def buscarPivote(self, filas, col, M):
        indiceFila = -1
        maxNum = np.inf *-1
        for i in range(col+1, filas):
            if(M[i][col] > maxNum and M[i][col] != 0):
                indiceFila = i
                maxNum = M[i][col]
        return indiceFila
 
    def eliminacionGaussiana(self, f, c, M):
        # Definición de variables
        indicePiv = -1
        
        for i in range(f):
            pivote = M[i][i]
            if pivote == 0:
                indicePiv = self.buscarPivote(f, i, M) # Se implementa pivoteo parcial
                #TODO: Implementar pivoteo completo
                if indicePiv == -1:
                    print("El sistema no tiene solución")
                    exit(0)
                else:
                    M = self.intercambiarFilas(indicePiv, i, M)
                    pivote = M[i][i]
            
            for j in range(i+1, f): # Realizar la eliminación de los elementos debajo del pivote
                if M[j][i] != 0:
                    k = pivote / M[j][i]    # Multiplicador para la eliminación
                    M = self.multiplicarFila(k, j, i, M)
                    M = self.restarFilas(j, i, M)
 
    def GJ(self,f,c,M):
        for i in range(f):
            pivote=M[f-1-i][f-1-i]
            M[f-1-i]=M[f-1-i]/pivote
            for j in range(f-1-i):
              M[j]=M[j]-M[j][f-1-i]*M[f-1-i]
 
class Graph():
 
  def plotScatter(self,X,Y,lab):
    plt.scatter(X,Y,c="black",label=lab)
    plt.title("Diagrama de dispersión")
    plt.xlabel("X")
    plt.ylabel("Y")
 
  def plotLine(self,func,a,b,lab,col):
    X=np.arange(a,b+0.1,0.1)
    Y=np.zeros_like(X)
 
    for i in range(len(X)):
      Y[i]=func.subs(x,X[i])
 
    plt.plot(X,Y,"--",color=col,label=lab)
    plt.legend(loc="best")
 
class Regression():
 
  def suma(self,X,grado):
    suma=0
    for i in range(len(X)):
      suma+=X[i]**grado
    
    return suma
 
  def sumaResultados(self,X,Y,grado):
    suma=0
    for i in range(len(X)):
      suma+=Y[i]*(X[i]**grado)
    return suma
 
  def mean(self,X):
    suma=0
    for i in range(len(X)):
      suma=suma+X[i]
    return suma/len(X)
 
  def error(self,YPred,Y):
    error=0
    for i in range(len(YPred)):
      error=error+(YPred[i]-Y[i])**2
    return error/len(Y)
 
  def linealRegression(self,xi,yi,n):
    obj=Regression()
    suma1,suma2,suma3,suma4=0,0,0,0
    for i in range(n):
      suma1=suma1+(xi[i]*yi[i])
      suma2=suma2+xi[i]
      suma3=suma3+yi[i]
      suma4=suma4+(xi[i]**2)
 
    numerador=n*suma1-(suma2*suma3)
    denominador=n*suma4-(suma2**2)
    a1=numerador/denominador
 
    a0=obj.mean(yi)-a1*obj.mean(xi)
 
    # Función
    f=a1*x+a0
    print("Regresión lineal:",f)
 
    # Valores de "Y" de regresión
    yPred=[]
    for i in range(n):
      yPred.append(f.subs(x,xi[i]))
 
    # Error cuadrático
    errorCuadratic=obj.error(yPred,yi)
    print("Error cuadrático medio:",errorCuadratic)
 
    return f,yPred,errorCuadratic
 
 
  def poliRegression(self,X,Y,n,m):
    obj=Regression()
 
    M=np.zeros((m+1,m+2))
    M[0][0]=n
 
    for i in range(m+1):
      for j in range(m+1):
        M[i][j]=obj.suma(X,i+j)
 
    for i in range(m+1):
      M[i][-1]=obj.sumaResultados(X,Y,i)
 
    objG = GaussJordan() 
    f=len(M)
    c=len(M[0])
    objG.eliminacionGaussiana(f, c, M) 
    objG.GJ(f,c,M) 
    
    # Función
    f=0
    for i in range(m+1):
      f+=M[i][-1]*(x**i)
    print("Regresión grado "+str(m)+":",f)
    
    # Valores de "Y" de regresión
    yPred=[]
    for i in range(n):
      yPred.append(f.subs(x,X[i]))
 
    # Error cuadrático
    errorCuadratic=obj.error(yPred,Y)
    print("Error cuadrático:",errorCuadratic)
 
    return f,yPred,errorCuadratic
 
def main():
  # Importación de datos
  df=pd.read_csv("https://raw.githubusercontent.com/brunolopez941/PracticasComputacionII/main/absolute-increase-global-population.csv")
  df1=df[["Year","Absolute increase in population (OWID based on HYDE & UN)"]]
  dfNuevo=df1[11990:12017]
  dfNuevo.columns=["Año","Población"]

  X=dfNuevo.Año.to_numpy()
  Y=dfNuevo.Población.to_numpy()

  n=len(X)

  objG=Graph()
  objG.plotScatter(X,Y,"Datos")
  plt.show()
 
  # Regresión lineal por mínimos cuadrados
  objLR=Regression()
  funcL,yPrediction,error=objLR.linealRegression(X,Y,n)

  # Grados
  grades=[1,2,4,6,8,10]
 
  # Regresión polinomial
  print()
  objPR=Regression()
  funcP=[]
  yPrediction=[]
  errors=[]

  # Colores
  colors=["purple","red","green","blue","gray","orange"]
 
  # Graficación
  objG.plotScatter(X,Y,"Datos")
  objG.plotLine(funcL,X[0],X[-1],"Regresión lineal","purple")
  for i in range(len(grades)):
    func,yP,error=objPR.poliRegression(X,Y,n,grades[i])
    print()
    funcP.append(func)
    yPrediction.append(yP)
    errors.append(error)
    objG.plotScatter(X,Y,"Datos")
    objG.plotLine(funcP[i],X[0],X[-1],"Regresión grado "+str(grades[i]),colors[i])
    plt.show()

  # Graficar errores
  plt.plot(grades, errors,marker="o",c="black")
  plt.title("Error cuadrático medio en escala logarítmica")
  plt.xlabel("Grado de regresión")
  plt.ylabel("Error cuadrático medio")
  plt.yscale('log')

if __name__=="__main__":
  main()